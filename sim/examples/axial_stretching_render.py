""" Rendering Script using POVray for Axial Stretching Test

This script reads the data file from the axial_stretching_test.py simulation
to render a POVray animation movie. The data file should contain a dictionary
of position vectors and times.

The script supports multiple camera positions, where a video is generated
for each camera view.

Notes
-----
    The module requires POVray installed.
    The simulation script must be modified to save the entire rod's
    position history ('position_collection') in the pickled data file.
"""

import multiprocessing
import os
from functools import partial
from multiprocessing import Pool

import numpy as np
from scipy import interpolate
from tqdm import tqdm

from _povmacros import Stages, pyelastica_rod, render

# Setup (USER DEFINE)
# This should point to the data file generated by the modified axial_stretching_test.py
DATA_PATH = "axial_stretching_data.dat"
SAVE_PICKLE = True

# Rendering Configuration (USER DEFINE)
OUTPUT_FILENAME = "pov_axial_stretching"
OUTPUT_IMAGES_DIR = "frames"
FPS = 10.0
WIDTH = 1920
HEIGHT = 1080
DISPLAY_FRAMES = "Off"  # Display povray images during the rendering. ['On', 'Off']

# Camera/Light Configuration (USER DEFINE)
# The rod is 1.0m long, aligned with the x-axis, and stretches.
stages = Stages()
stages.add_camera(
    # Add a side-on perspective view
    location=[0.5, 0.5, -4.0],  # Centered on the rod, raised slightly, and pulled back
    angle=25,
    look_at=[0.5, 0.0, 0.0],  # Look at the center of the rod at rest
    name="side_view",
)
stages.add_camera(
    # Add a close-up view of the stretching tip
    location=[1.0, 0.2, -1.5],  # Positioned near the tip
    angle=30,
    look_at=[1.0, 0.0, 0.0],  # Look directly at the tip
    name="tip_closeup",
)
stages.add_light(
    # Sun light
    position=[1500, 2500, 1000],
    color="White",
    camera_id=-1,  # Global light for all cameras
)
stages.add_light(
    # Fill light for side_view camera
    position=[0.5, 0.5, -4.0],
    color=[0.1, 0.1, 0.1],
    camera_id=0,
)
stages.add_light(
    # Fill light for tip_closeup camera
    position=[1.0, 0.2, -1.5],
    color=[0.1, 0.1, 0.1],
    camera_id=1,
)
stage_scripts = stages.generate_scripts()

# Externally Including Files (USER DEFINE)
# You can include a grid or axes for better visualization of the stretching.
# For example, create a 'grid.inc' file with a POV-Ray grid object.
included = ["default.inc", "colors.inc"] # "grid.inc"

# Multiprocessing Configuration (USER DEFINE)
MULTIPROCESSING = True
THREAD_PER_AGENT = 4  # Number of threads to use per rendering process.
NUM_AGENT = multiprocessing.cpu_count() // 2  # Number of parallel rendering agents.

# Execute
if __name__ == "__main__":
    # Load Data
    assert os.path.exists(DATA_PATH), f"Data file '{DATA_PATH}' not found."
    try:
        if SAVE_PICKLE:
            import pickle as pk

            with open(DATA_PATH, "rb") as fptr:
                # The data is expected to be the 'recorded_history' dictionary
                data = pk.load(fptr)
        else:
            raise NotImplementedError("Only pickled data is supported")
    except OSError as err:
        print(f"Cannot open the datafile {DATA_PATH}")
        print(str(err))
        raise

    # Convert data to numpy array
    times = np.array(data["time"])  # shape: (timelength)
    # The 'position' key should contain a list of (3, n_elem) arrays
    xs = np.array(data["position"])  # shape: (timelength, 3, num_element)

    # Interpolate Data
    # This smooths the animation and matches the desired FPS.
    runtime = times.max()
    total_frame = int(runtime * FPS)
    recorded_frame = times.shape[0]
    print(f"Interpolating {recorded_frame} data points to {total_frame} video frames.")
    times_true = np.linspace(0, runtime, total_frame)

    # Use interpolation function for positions and times
    f_xs = interpolate.interp1d(times, xs, axis=0)
    xs = f_xs(times_true)
    f_times = interpolate.interp1d(times, times, axis=0)
    times = f_times(times_true)
    
    # Set the rod radius based on the simulation parameters
    base_radius = np.ones_like(xs[:, 0, :]) * 0.025

    # Rendering
    # For each frame, a '.pov' script file is generated.
    batch = []
    for view_name in stage_scripts.keys():  # Make Directory for each view
        output_path = os.path.join(OUTPUT_IMAGES_DIR, view_name)
        os.makedirs(output_path, exist_ok=True)

    for frame_number in tqdm(range(total_frame), desc="Generating Scripts"):
        for view_name, stage_script in stage_scripts.items():
            output_path = os.path.join(OUTPUT_IMAGES_DIR, view_name)

            # Collect povray scripts
            script = []
            script.extend([f'#include "{s}"' for s in included])
            script.append(stage_script)
            
            # Add a floor plane for context
            script.append("plane{y, -0.025 pigment{color Gray50}}")

            # Generate the rod object for the current frame
            rod_object = pyelastica_rod(
                x=xs[frame_number],
                r=base_radius[frame_number],
                color="rgb<0.8, 0.2, 0.2>",  # A reddish color for the rod
            )
            script.append(rod_object)
            pov_script = "\n".join(script)

            # Write .pov script file
            file_path = os.path.join(output_path, f"frame_{frame_number:05d}")
            with open(file_path + ".pov", "w+") as f:
                f.write(pov_script)
            batch.append(file_path)

    # Process POVray
    # Each '.pov' script is rendered into a '.png' image.
    pbar = tqdm(total=len(batch), desc="Rendering Frames")
    if MULTIPROCESSING:
        func = partial(
            render,
            width=WIDTH,
            height=HEIGHT,
            display=DISPLAY_FRAMES,
            pov_thread=THREAD_PER_AGENT,
        )
        with Pool(NUM_AGENT) as p:
            for _ in p.imap_unordered(func, batch):
                pbar.update()
    else:
        for filename in batch:
            render(
                filename,
                width=WIDTH,
                height=HEIGHT,
                display=DISPLAY_FRAMES,
                pov_thread=multiprocessing.cpu_count(),
            )
            pbar.update()
    pbar.close()

    # Create Video using ffmpeg
    print("Combining frames into video...")
    for view_name in stage_scripts.keys():
        imageset_path = os.path.join(OUTPUT_IMAGES_DIR, view_name)
        video_filename = f"{OUTPUT_FILENAME}_{view_name}.mp4"
        
        # Use a 5-digit pattern to match the frame filenames
        ffmpeg_command = (
            f"ffmpeg -y -r {FPS} -i {imageset_path}/frame_%05d.png "
            f"-c:v libx264 -pix_fmt yuv420p {video_filename}"
        )
        
        print(f"Executing: {ffmpeg_command}")
        os.system(ffmpeg_command)
        print(f"Video saved as {video_filename}")